{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import os\n",
    "import timm\n",
    "import numpy as np\n",
    "import data.data as data\n",
    "import data.segmentation as segmentation\n",
    "import metrics.metrics as metrics\n",
    "import argparse\n",
    "import torch_optimizer as optimizer\n",
    "import wandb\n",
    "\n",
    "from config import settings\n",
    "\n",
    "import models.spinalnet_resnet as spinalnet_resnet\n",
    "import models.effnet as effnet\n",
    "import models.densenet as densenet\n",
    "import models.spinalnet_vgg as spinalnet_vgg\n",
    "import models.vitL16 as vitL16\n",
    "import models.alexnet_vgg as alexnet_vgg\n",
    "import models.resnet18 as resnet18\n",
    "\n",
    "from data.data import DataPart\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    ('ResNet18', resnet18.load_model()),\n",
    "    ('EfficientNet', effnet.load_model()),\n",
    "    ('DenseNet', densenet.load_model()),\n",
    "    ('SpinalNet_ResNet', spinalnet_resnet.load_model()),\n",
    "    ('SpinalNet_VGG', spinalnet_vgg.load_model()),\n",
    "    ('ViTL16', vitL16.load_model()),\n",
    "    ('AlexNet_VGG', alexnet_vgg.load_model())\n",
    "]\n",
    "\n",
    "all_optimizers = [\n",
    "    ('SGD', optim.SGD),\n",
    "    ('Rprop', optim.Rprop),\n",
    "    ('Adam', optim.Adam),\n",
    "    ('NAdam', optim.NAdam),\n",
    "    ('RAdam', optim.RAdam),\n",
    "    ('AdamW', optim.AdamW),\n",
    "    #('Adagrad', optim.Adagrad),\n",
    "    ('RMSprop', optim.RMSprop),\n",
    "    #('Adadelta', optim.Adadelta),\n",
    "    ('DiffGrad', optimizer.DiffGrad),\n",
    "    # ('LBFGS', optim.LBFGS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_, dataloaders = data.create_dataloaders()\n",
    "\n",
    "train_loader = dataloaders[DataPart.TRAIN]\n",
    "val_loader = dataloaders[DataPart.VALIDATE]\n",
    "test_loader = dataloaders[DataPart.TEST_DR5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description='Model training')\n",
    "# parser.add_argument('--models', nargs='+', default=['ResNet18', 'EfficientNet', 'DenseNet', 'SpinalNet_ResNet', 'SpinalNet_VGG', 'ViTL16', 'AlexNet_VGG'],\n",
    "#                     help='List of models to train (default: all)')\n",
    "# parser.add_argument('--epochs', type=int, default=5, help='Number of epochs to train (default: 5)')\n",
    "# parser.add_argument('--lr', type=float, default=0.0001, help='Learning rate for optimizer (default: 0.0001)')\n",
    "# parser.add_argument('--mm', type=float, default=0.9, help='Momentum for optimizer (default: 0.9)')\n",
    "# parser.add_argument('--optimizer', choices=[name for name, _ in all_optimizers], default='Adam', help='Optimizer to use (default: Adam)')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# selected_models = [(model_name, model) for model_name, model in models if model_name in args.models]\n",
    "\n",
    "# num_epochs = args.epochs\n",
    "# lr = args.lr\n",
    "# momentum = args.mm\n",
    "# optimizer_name = args.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = all_models[:1]\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "optimizer_name = \"Adam\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings.wandb_api_token:\n",
    "    wandb.login(key=settings.wandb_api_token)\n",
    "    wandb.init(project='cluster-search', reinit=True)\n",
    "else:\n",
    "    wandb.init(project='cluster-search', reinit=True)\n",
    "\n",
    "\n",
    "wandb.config.models = [name for name, _ in selected_models]\n",
    "wandb.config.num_epochs = num_epochs\n",
    "wandb.config.lr = lr\n",
    "wandb.config.momentum = momentum\n",
    "wandb.config.optimizer = optimizer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "results = {}\n",
    "val_results = {}\n",
    "classes = ('random', 'clusters')\n",
    "\n",
    "\n",
    "\n",
    "for model_name, model in selected_models:\n",
    "    optimizer_class = dict(all_optimizers)[optimizer_name]\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum) if optimizer_name in ['SGD', 'RMSprop'] else optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "    \n",
    "\n",
    "    losses, epochs, accuracies, val_losses, val_accuracies, model_X = train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "    results[model_name] = {'losses': losses, 'epochs': epochs, 'accuracies': accuracies}\n",
    "    val_results[model_name] = {'val_losses': val_losses, 'val_epochs': epochs, 'val_accuracies': val_accuracies}\n",
    "\n",
    "# filepath = \"/content/trained_models/ResNet_epoch_3.pth\"\n",
    "#\n",
    "# for model_name, model in models:\n",
    "#     losses, epochs, accuracies = continue_training(model, train_loader, criterion, optimizer, device, num_epochs, filepath)\n",
    "#     results[model_name].update({'losses': losses, 'epochs': epochs, 'accuracies': accuracies})\n",
    "# \n",
    "    for epoch in range(num_epochs):\n",
    "        wandb.log({f'{model_name}_{optimizer_name}_train_loss': losses[epoch], f'{model_name}_{optimizer_name}_train_accuracy': accuracies[epoch], 'epoch': epochs[epoch]})\n",
    "        wandb.log({f'{model_name}_{optimizer_name}_val_loss': val_losses[epoch], f'{model_name}_{optimizer_name}_val_accuracy': val_accuracies[epoch], 'epoch': epochs[epoch]})\n",
    "    \n",
    "\n",
    "    train_table = wandb.Table(data=[[epochs[i], losses[i], accuracies[i]] for i in range(num_epochs)],\n",
    "                          columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "\n",
    "    val_table = wandb.Table(data=[[epochs[i], val_losses[i], val_accuracies[i]] for i in range(num_epochs)],\n",
    "                            columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "\n",
    "    wandb.log({\"Train Metrics\": train_table, \"Validation Metrics\": val_table})\n",
    "    # wandb.log({f'{model_name}_{optimizer_name}_train_loss': wandb.plot.line_series(xs=np.array([epochs] * len(losses)), ys=np.array(losses), title=f'{model_name}_{optimizer_name} Training Loss')})\n",
    "    # wandb.log({f'{model_name}_{optimizer_name}_val_loss': wandb.plot.line_series(xs=np.array([epochs] * len(val_losses)), ys=np.array(val_losses), title=f'{model_name}_{optimizer_name} Validation Loss')})\n",
    "\n",
    "    model_weights = []\n",
    "    # for name, param in model.named_parameters():\n",
    "    #    if 'weight' in name:\n",
    "    #        model_weights.extend(param.detach().cpu().numpy().flatten())\n",
    "    # wandb.log({f'{model_name}_{optimizer_name}_model_weights': wandb.Histogram(model_weights)})\n",
    "    \n",
    "    #for name, param in model.named_parameters():\n",
    "    #    if param.grad is not None:\n",
    "    #        wandb.log({f'{model_name}_{optimizer_name}_gradient_{name}': wandb.Histogram(param.grad.detach().cpu().numpy().flatten())})\n",
    "\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    for model_name, data in results.items():\n",
    "        np.savez(f'results/{model_name}_{optimizer_name}_results.npz', losses=data['losses'], epochs=data['epochs'], accuracies=data['accuracies'])\n",
    "\n",
    "    for model_name, data in val_results.items():\n",
    "        np.savez(f'results/{model_name}_{optimizer_name}_val_results.npz', losses=data['val_losses'], epochs=data['val_epochs'], accuracies=data['val_accuracies'])\n",
    "\n",
    "    y_pred, y_probs, y_true = [], [], []\n",
    "\n",
    "    #device = torch.device(\"cpu\")\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        output = model_X(inputs) # Feed Network\n",
    "        y_probs.extend(output.data.cpu().numpy().ravel())\n",
    "        output = [1 if (i > 0.9) else 0 for i in output]\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "    # confusion_matrix = metrics.plot_confusion_matrix(y_true, y_pred) TO DO\n",
    "    # wandb.log({f'{model_name}_{optimizer_name}_confusion_matrix': confusion_matrix})\n",
    "    # wandb.log({f'{model_name}_{optimizer_name}_probabilities': wandb.Histogram(np.array(y_probs))})\n",
    "\n",
    "    metrics.modelPerformance(model_name, optimizer_name, y_true, y_pred, y_probs, classes, results[model_name], val_results[model_name])\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "wandb_run = wandb.run\n",
    "if wandb_run:\n",
    "    logged_metrics = wandb_run.history()\n",
    "    print(\"Logged Metrics:\")\n",
    "    for key, value in logged_metrics.items():\n",
    "        print(key, \":\", value)\n",
    "else:\n",
    "    print(\"No wandb run found.\")\n",
    "\n",
    "segmentation.saveSegMaps(selected_models, optimizer_name)\n",
    "segmentation.saveBigSegMap(selected_models, optimizer_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
