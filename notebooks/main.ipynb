{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import timm\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import torch_optimizer as optimizer\n",
    "import wandb\n",
    "\n",
    "from config import settings\n",
    "\n",
    "import models.spinalnet_resnet as spinalnet_resnet\n",
    "import models.effnet as effnet\n",
    "import models.densenet as densenet\n",
    "import models.spinalnet_vgg as spinalnet_vgg\n",
    "import models.vitL16 as vitL16\n",
    "import models.alexnet_vgg as alexnet_vgg\n",
    "import models.resnet18 as resnet18\n",
    "\n",
    "import  data\n",
    "# import data.segmentation as segmentation\n",
    "# import metrics.metrics as metrics\n",
    "from data import DataPart\n",
    "from train import Trainer\n",
    "import metrics\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    ('ResNet18', resnet18.load_model()),\n",
    "    ('EfficientNet', effnet.load_model()),\n",
    "    ('DenseNet', densenet.load_model()),\n",
    "    ('SpinalNet_ResNet', spinalnet_resnet.load_model()),\n",
    "    ('SpinalNet_VGG', spinalnet_vgg.load_model()),\n",
    "    ('ViTL16', vitL16.load_model()),\n",
    "    ('AlexNet_VGG', alexnet_vgg.load_model())\n",
    "]\n",
    "\n",
    "all_optimizers = [\n",
    "    ('SGD', optim.SGD),\n",
    "    ('Rprop', optim.Rprop),\n",
    "    ('Adam', optim.Adam),\n",
    "    ('NAdam', optim.NAdam),\n",
    "    ('RAdam', optim.RAdam),\n",
    "    ('AdamW', optim.AdamW),\n",
    "    #('Adagrad', optim.Adagrad),\n",
    "    ('RMSprop', optim.RMSprop),\n",
    "    #('Adadelta', optim.Adadelta),\n",
    "    ('DiffGrad', optimizer.DiffGrad),\n",
    "    # ('LBFGS', optim.LBFGS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mszekhov/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "252\n",
      "84\n",
      "84\n",
      "244\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "datasets, dataloaders = data.create_dataloaders()\n",
    "\n",
    "train_loader = dataloaders[DataPart.TRAIN]\n",
    "val_loader = dataloaders[DataPart.VALIDATE]\n",
    "test_loader = dataloaders[DataPart.TEST_DR5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parser = argparse.ArgumentParser(description='Model training')\n",
    "# parser.add_argument('--models', nargs='+', default=['ResNet18', 'EfficientNet', 'DenseNet', 'SpinalNet_ResNet', 'SpinalNet_VGG', 'ViTL16', 'AlexNet_VGG'],\n",
    "#                     help='List of models to train (default: all)')\n",
    "# parser.add_argument('--epochs', type=int, default=5, help='Number of epochs to train (default: 5)')\n",
    "# parser.add_argument('--lr', type=float, default=0.0001, help='Learning rate for optimizer (default: 0.0001)')\n",
    "# parser.add_argument('--mm', type=float, default=0.9, help='Momentum for optimizer (default: 0.9)')\n",
    "# parser.add_argument('--optimizer', choices=[name for name, _ in all_optimizers], default='Adam', help='Optimizer to use (default: Adam)')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# selected_models = [(model_name, model) for model_name, model in models if model_name in args.models]\n",
    "\n",
    "# num_epochs = args.epochs\n",
    "# lr = args.lr\n",
    "# momentum = args.mm\n",
    "# optimizer_name = args.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = all_models[:2]\n",
    "\n",
    "num_epochs = 1\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "optimizer_name = \"Adam\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzehov1\u001b[0m (\u001b[33mmzekhov\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/mszekhov/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/mszekhov/Desktop/current_projects/galaxyHackers/wandb/run-20240731_010451-1s6iajtr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mzekhov/cluster-search/runs/1s6iajtr' target=\"_blank\">magic-wildflower-41</a></strong> to <a href='https://wandb.ai/mzekhov/cluster-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mzekhov/cluster-search' target=\"_blank\">https://wandb.ai/mzekhov/cluster-search</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mzekhov/cluster-search/runs/1s6iajtr' target=\"_blank\">https://wandb.ai/mzekhov/cluster-search/runs/1s6iajtr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if settings.wandb_api_token:\n",
    "    wandb.login(key=settings.wandb_api_token)\n",
    "    wandb.init(project='cluster-search', config={}, reinit=True)\n",
    "else:\n",
    "    wandb.init(project='cluster-search', config={}, reinit=True)\n",
    "\n",
    "\n",
    "wandb.config.models = [name for name, _ in selected_models]\n",
    "wandb.config.num_epochs = num_epochs\n",
    "wandb.config.lr = lr\n",
    "wandb.config.momentum = momentum\n",
    "wandb.config.optimizer = optimizer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "results = {}\n",
    "val_results = {}\n",
    "\n",
    "classes = ('random', 'clusters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:56<00:00,  8.12s/batch]      | 0/1 [00:00<?, ?epoch/s]\n",
      "100%|██████████| 7/7 [00:24<00:00,  3.47s/it]\n",
      "100%|██████████| 7/7 [00:19<00:00,  2.76s/it]                                          \n",
      "100%|██████████| 7/7 [03:57<00:00, 33.86s/batch]          | 0/1 [00:00<?, ?epoch/s]\n",
      "100%|██████████| 7/7 [05:03<00:00, 43.42s/it]\n",
      " 57%|█████▋    | 4/7 [01:39<01:26, 28.72s/it]                                               Python(84190) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84255) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84309) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84391) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84409) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84458) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84535) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84606) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84650) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84742) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84795) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 71%|███████▏  | 5/7 [02:37<01:18, 39.19s/it]Python(84801) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84840) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84917) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84957) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84996) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(84997) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85036) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85075) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85114) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85153) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85231) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85347) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85386) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      " 86%|████████▌ | 6/7 [03:25<00:42, 42.37s/it]Python(85387) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85464) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85544) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(85585) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|██████████| 7/7 [03:53<00:00, 33.42s/it]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in selected_models:\n",
    "     optimizer_class = dict(all_optimizers)[optimizer_name]\n",
    "\n",
    "     if optimizer_name in ['SGD', 'RMSprop']:\n",
    "          optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum) \n",
    "     else:\n",
    "          optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "         \n",
    "     trainer = Trainer(\n",
    "          model=model,\n",
    "          criterion=criterion,\n",
    "          optimizer=optimizer,\n",
    "          train_dataloader=train_loader,\n",
    "          val_dataloader=val_loader,\n",
    "\n",
    "     )\n",
    "\n",
    "     trainer.train(num_epochs)\n",
    "\n",
    "     for step in range(trainer.global_step):\n",
    "          wandb.log(\n",
    "               {\n",
    "                    f'{model_name}_{optimizer_name}_train_loss': trainer.history['train_loss'][step], \n",
    "                    f'{model_name}_{optimizer_name}_train_accuracy':trainer.history['train_acc'][step], \n",
    "                    'global_step': step + 1})\n",
    "          \n",
    "     for epoch in range(num_epochs):\n",
    "          wandb.log(\n",
    "               {\n",
    "                    f'{model_name}_{optimizer_name}_val_loss': trainer.history['val_loss'][epoch], \n",
    "                    f'{model_name}_{optimizer_name}_val_accuracy': trainer.history['val_acc'][epoch], \n",
    "                    'epoch': epoch})\n",
    "\n",
    "     \n",
    "     train_table = wandb.Table(\n",
    "          data=[\n",
    "               [\n",
    "                    step, \n",
    "                    trainer.history['train_loss'][step], \n",
    "                    trainer.history['train_acc'][step]\n",
    "               ] for step in range(trainer.global_step)],\n",
    "          columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "\n",
    "     val_table = wandb.Table(\n",
    "          data=[\n",
    "               [\n",
    "                    epoch, \n",
    "                    trainer.history['val_loss'][epoch], \n",
    "                    trainer.history['val_acc'][epoch]\n",
    "               ] for epoch in range(num_epochs)],\n",
    "          columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "\n",
    "     wandb.log({\"Train Metrics\": train_table, \"Validation Metrics\": val_table})\n",
    "\n",
    "     y_pred, y_probs, y_true, *_ = trainer.test(test_loader)\n",
    "\n",
    "     metrics.modelPerformance(model_name, optimizer_name, y_true, y_pred, y_probs, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(85646) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3af17f8f455471797d8fe9e0116a2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.013 MB uploaded\\r'), FloatProgress(value=0.38068348489293047, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>EfficientNet_Adam_train_accuracy</td><td>▁▆█▇█▆█</td></tr><tr><td>EfficientNet_Adam_train_loss</td><td>█▇▆▅▄▅▁</td></tr><tr><td>EfficientNet_Adam_val_accuracy</td><td>▁</td></tr><tr><td>EfficientNet_Adam_val_loss</td><td>▁</td></tr><tr><td>ResNet18_Adam_train_accuracy</td><td>▁▂▄▄▃▇█</td></tr><tr><td>ResNet18_Adam_train_loss</td><td>█▇▅▅▅▁▁</td></tr><tr><td>ResNet18_Adam_val_accuracy</td><td>▁</td></tr><tr><td>ResNet18_Adam_val_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>global_step</td><td>▁▂▃▅▆▇█▁▂▃▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>EfficientNet_Adam_train_accuracy</td><td>0.75</td></tr><tr><td>EfficientNet_Adam_train_loss</td><td>0.60145</td></tr><tr><td>EfficientNet_Adam_val_accuracy</td><td>0.48214</td></tr><tr><td>EfficientNet_Adam_val_loss</td><td>0.69571</td></tr><tr><td>ResNet18_Adam_train_accuracy</td><td>0.75</td></tr><tr><td>ResNet18_Adam_train_loss</td><td>0.56337</td></tr><tr><td>ResNet18_Adam_val_accuracy</td><td>0.57589</td></tr><tr><td>ResNet18_Adam_val_loss</td><td>0.6533</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>global_step</td><td>7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-wildflower-41</strong> at: <a href='https://wandb.ai/mzekhov/cluster-search/runs/1s6iajtr' target=\"_blank\">https://wandb.ai/mzekhov/cluster-search/runs/1s6iajtr</a><br/> View project at: <a href='https://wandb.ai/mzekhov/cluster-search' target=\"_blank\">https://wandb.ai/mzekhov/cluster-search</a><br/>Synced 5 W&B file(s), 4 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240731_010451-1s6iajtr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No wandb run found.\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n",
    "\n",
    "wandb_run = wandb.run\n",
    "if wandb_run:\n",
    "    logged_metrics = wandb_run.history()\n",
    "    print(\"Logged Metrics:\")\n",
    "    for key, value in logged_metrics.items():\n",
    "        print(key, \":\", value)\n",
    "else:\n",
    "    print(\"No wandb run found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'segmentation' from '/Users/mszekhov/Desktop/current_projects/galaxyHackers/segmentation.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation\n",
    "\n",
    "from importlib import reload\n",
    "reload(data)\n",
    "reload(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "from config import settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mszekhov/Desktop/current_projects/galaxyHackers'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:27<00:00,  3.99s/it]\n",
      "100%|██████████| 7/7 [00:25<00:00,  3.62s/it]\n",
      "  0%|          | 0/7 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_name, model \u001b[38;5;241m=\u001b[39m selected_models[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[43msegmentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_segmentation_plots\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_name\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/segmentation.py:333\u001b[0m, in \u001b[0;36mcreate_segmentation_plots\u001b[0;34m(model, model_name, optimizer_name, map_type)\u001b[0m\n\u001b[1;32m    330\u001b[0m predictor \u001b[38;5;241m=\u001b[39m Predictor(model, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(SampleName):\n\u001b[0;32m--> 333\u001b[0m     \u001b[43mcreate_segmentation_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/segmentation.py:293\u001b[0m, in \u001b[0;36mcreate_segmentation_plot\u001b[0;34m(model_name, optimizer_name, predictor, sample_name, n_cols)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     cur_ax \u001b[38;5;241m=\u001b[39m axes\n\u001b[0;32m--> 293\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(settings\u001b[38;5;241m.\u001b[39mSEGMENTATION_SAMPLES_PATH, sample_name\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;28mstr\u001b[39m(idx), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m predictions\u001b[38;5;241m.\u001b[39mto_csv(path)\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/train.py:200\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m    198\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 200\u001b[0m     logits, outputs, idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mextend(outputs)\n\u001b[1;32m    203\u001b[0m     y_prob\u001b[38;5;241m.\u001b[39mextend(logits[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/train.py:226\u001b[0m, in \u001b[0;36mPredictor.compute_all\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mlist\u001b[39m(batch\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m--> 226\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, outputs, idx\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/models/resnet18.py:19\u001b[0m, in \u001b[0;36mResNet18.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/current_projects/galaxyHackers/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import segmentation\n",
    "import traceback\n",
    "\n",
    "model_name, model = selected_models[0]\n",
    "segmentation.create_segmentation_plots(\n",
    "    model,\n",
    "    model_name,\n",
    "    optimizer_name=optimizer_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n"
     ]
    }
   ],
   "source": [
    "n_rows = 2\n",
    "n_cols = 5\n",
    "for i in range(10):   \n",
    "    cur_row = i // n_cols\n",
    "    cur_col = i % n_cols\n",
    "    print(cur_row, cur_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NoneType: None\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "traceback.format_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "from config import settings\n",
    "\n",
    "dataset = data.ClusterDataset(\n",
    "        \"/Users/mszekhov/Desktop/current_projects/galaxyHackers/storage/segmentation/samples/cluster/758\",\n",
    "        \"/Users/mszekhov/Desktop/current_projects/galaxyHackers/storage/segmentation/samples/cluster/758/description.csv\",\n",
    "        transform=transforms.Compose(data.main_transforms),\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=settings.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '1', 2, '3', 4, '5', 6, '7', 8, '9']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) if i%2 else i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'image'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m      5\u001b[0m batch\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.keys())\n",
    "    raise\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "фю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': ['0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30',\n",
       "  '31',\n",
       "  '32',\n",
       "  '33',\n",
       "  '34',\n",
       "  '35',\n",
       "  '36',\n",
       "  '37',\n",
       "  '38',\n",
       "  '39',\n",
       "  '40',\n",
       "  '41',\n",
       "  '42',\n",
       "  '43',\n",
       "  '44',\n",
       "  '45',\n",
       "  '46',\n",
       "  '47',\n",
       "  '48',\n",
       "  '49',\n",
       "  '50',\n",
       "  '51',\n",
       "  '52',\n",
       "  '53',\n",
       "  '54',\n",
       "  '55',\n",
       "  '56',\n",
       "  '57',\n",
       "  '58',\n",
       "  '59',\n",
       "  '60',\n",
       "  '61',\n",
       "  '62',\n",
       "  '63'],\n",
       " 'image': tensor([[[[-1.6555, -1.6555, -1.6384,  ..., -1.6213, -1.6213, -1.6213],\n",
       "           [-1.6555, -1.6555, -1.6384,  ..., -1.6213, -1.6213, -1.6213],\n",
       "           [-1.6555, -1.6555, -1.6384,  ..., -1.6213, -1.6213, -1.6213],\n",
       "           ...,\n",
       "           [-1.6898, -1.6898, -1.6898,  ..., -1.6898, -1.6898, -1.6898],\n",
       "           [-1.6898, -1.6898, -1.6898,  ..., -1.6898, -1.6898, -1.6898],\n",
       "           [-1.6898, -1.6898, -1.6898,  ..., -1.6898, -1.6898, -1.6898]],\n",
       " \n",
       "          [[-1.5980, -1.5980, -1.5630,  ..., -1.5280, -1.5280, -1.5280],\n",
       "           [-1.5980, -1.5980, -1.5630,  ..., -1.5280, -1.5280, -1.5280],\n",
       "           [-1.5805, -1.5805, -1.5630,  ..., -1.5280, -1.5280, -1.5280],\n",
       "           ...,\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.5805, -1.5805, -1.5805],\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.5805, -1.5805, -1.5805],\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.5805, -1.5805, -1.5805]],\n",
       " \n",
       "          [[-1.3513, -1.3513, -1.3687,  ..., -1.2990, -1.2990, -1.2990],\n",
       "           [-1.3513, -1.3513, -1.3687,  ..., -1.2990, -1.2990, -1.2990],\n",
       "           [-1.3861, -1.3861, -1.3687,  ..., -1.2990, -1.2990, -1.2990],\n",
       "           ...,\n",
       "           [-1.3513, -1.3513, -1.3513,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3513, -1.3513, -1.3513,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3513, -1.3513, -1.3513,  ..., -1.3164, -1.3164, -1.3164]]],\n",
       " \n",
       " \n",
       "         [[[-1.6555, -1.6555, -1.6555,  ..., -1.6384, -1.6384, -1.6384],\n",
       "           [-1.6555, -1.6555, -1.6555,  ..., -1.6384, -1.6384, -1.6384],\n",
       "           [-1.6555, -1.6555, -1.6555,  ..., -1.6384, -1.6384, -1.6213],\n",
       "           ...,\n",
       "           [-1.7240, -1.7240, -1.7240,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           [-1.7069, -1.7069, -1.7069,  ..., -1.6898, -1.6898, -1.6898],\n",
       "           [-1.7069, -1.7069, -1.7069,  ..., -1.6898, -1.6898, -1.6898]],\n",
       " \n",
       "          [[-1.5630, -1.5630, -1.5630,  ..., -1.5455, -1.5455, -1.5455],\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.5455, -1.5455, -1.5455],\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.5455, -1.5455, -1.5280],\n",
       "           ...,\n",
       "           [-1.6155, -1.6155, -1.6155,  ..., -1.5630, -1.5630, -1.5630],\n",
       "           [-1.6331, -1.6331, -1.6331,  ..., -1.5805, -1.5805, -1.5805],\n",
       "           [-1.6331, -1.6331, -1.6331,  ..., -1.5805, -1.5805, -1.5805]],\n",
       " \n",
       "          [[-1.3339, -1.3339, -1.3339,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3339, -1.3339, -1.3339,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3339, -1.3339, -1.3339,  ..., -1.3164, -1.3164, -1.2990],\n",
       "           ...,\n",
       "           [-1.3164, -1.3164, -1.3164,  ..., -1.2990, -1.2990, -1.2990],\n",
       "           [-1.3164, -1.3164, -1.3164,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3164, -1.3164, -1.3164,  ..., -1.3164, -1.3164, -1.3164]]],\n",
       " \n",
       " \n",
       "         [[[-1.3644, -1.3473, -1.3130,  ..., -1.5357, -1.5357, -1.5357],\n",
       "           [-1.3473, -1.3473, -1.2959,  ..., -1.5357, -1.5357, -1.5357],\n",
       "           [-1.2959, -1.2959, -1.2788,  ..., -1.5870, -1.5870, -1.5870],\n",
       "           ...,\n",
       "           [-1.6213, -1.6213, -1.6213,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           [-1.6213, -1.6213, -1.6213,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           [-1.6213, -1.6213, -1.6213,  ..., -1.6727, -1.6727, -1.6555]],\n",
       " \n",
       "          [[-1.1954, -1.1779, -1.1954,  ..., -1.5105, -1.4930, -1.4930],\n",
       "           [-1.1779, -1.1779, -1.1779,  ..., -1.5105, -1.4930, -1.4930],\n",
       "           [-1.1779, -1.1779, -1.1604,  ..., -1.5105, -1.5105, -1.5105],\n",
       "           ...,\n",
       "           [-1.5105, -1.5105, -1.5105,  ..., -1.5630, -1.5455, -1.5455],\n",
       "           [-1.4930, -1.4930, -1.5105,  ..., -1.5630, -1.5455, -1.5455],\n",
       "           [-1.4930, -1.4930, -1.5105,  ..., -1.5630, -1.5455, -1.5280]],\n",
       " \n",
       "          [[-0.9156, -0.8981, -0.9330,  ..., -1.3339, -1.3513, -1.3513],\n",
       "           [-0.8981, -0.8981, -0.9156,  ..., -1.3339, -1.3513, -1.3513],\n",
       "           [-0.9156, -0.9156, -0.8981,  ..., -1.3513, -1.3513, -1.3513],\n",
       "           ...,\n",
       "           [-1.2467, -1.2467, -1.2467,  ..., -1.2990, -1.3339, -1.3339],\n",
       "           [-1.2816, -1.2816, -1.2467,  ..., -1.2990, -1.3339, -1.3339],\n",
       "           [-1.2816, -1.2816, -1.2467,  ..., -1.2990, -1.3339, -1.3164]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.6555, -1.6555, -1.6384,  ..., -1.6898, -1.6898, -1.6898],\n",
       "           [-1.6555, -1.6384, -1.6384,  ..., -1.7069, -1.7069, -1.7069],\n",
       "           [-1.6384, -1.6384, -1.6213,  ..., -1.7069, -1.7240, -1.7240],\n",
       "           ...,\n",
       "           [-1.6384, -1.6384, -1.6384,  ..., -1.7069, -1.7069, -1.7069],\n",
       "           [-1.6384, -1.6384, -1.6213,  ..., -1.7069, -1.7412, -1.7412],\n",
       "           [-1.6384, -1.6384, -1.6213,  ..., -1.7240, -1.7412, -1.7412]],\n",
       " \n",
       "          [[-1.4930, -1.4930, -1.4755,  ..., -1.5805, -1.5805, -1.5805],\n",
       "           [-1.4930, -1.4755, -1.4755,  ..., -1.5980, -1.5980, -1.5980],\n",
       "           [-1.4755, -1.4755, -1.4580,  ..., -1.5980, -1.6155, -1.6155],\n",
       "           ...,\n",
       "           [-1.5455, -1.5455, -1.5455,  ..., -1.6155, -1.6155, -1.6155],\n",
       "           [-1.5455, -1.5455, -1.5280,  ..., -1.6331, -1.6331, -1.6331],\n",
       "           [-1.5455, -1.5455, -1.5280,  ..., -1.6506, -1.6331, -1.6331]],\n",
       " \n",
       "          [[-1.2119, -1.2119, -1.2293,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.2119, -1.1944, -1.2293,  ..., -1.3339, -1.3339, -1.3339],\n",
       "           [-1.1944, -1.1944, -1.1770,  ..., -1.3339, -1.3513, -1.3513],\n",
       "           ...,\n",
       "           [-1.3513, -1.3513, -1.3164,  ..., -1.3513, -1.3513, -1.3513],\n",
       "           [-1.3513, -1.3513, -1.2990,  ..., -1.3164, -1.3339, -1.3339],\n",
       "           [-1.3513, -1.3513, -1.2990,  ..., -1.3339, -1.3339, -1.3339]]],\n",
       " \n",
       " \n",
       "         [[[-1.6898, -1.6898, -1.6898,  ..., -1.6213, -1.6384, -1.6384],\n",
       "           [-1.6898, -1.6898, -1.6898,  ..., -1.6213, -1.6384, -1.6555],\n",
       "           [-1.6727, -1.6898, -1.6727,  ..., -1.6384, -1.6384, -1.6555],\n",
       "           ...,\n",
       "           [-1.6042, -1.5870, -1.5528,  ..., -1.6213, -1.6042, -1.6042],\n",
       "           [-1.6042, -1.5870, -1.5699,  ..., -1.6042, -1.6042, -1.5870],\n",
       "           [-1.6042, -1.5870, -1.5699,  ..., -1.6042, -1.6042, -1.5870]],\n",
       " \n",
       "          [[-1.5805, -1.5805, -1.5805,  ..., -1.5280, -1.5455, -1.5455],\n",
       "           [-1.5805, -1.5805, -1.5805,  ..., -1.5280, -1.5455, -1.5630],\n",
       "           [-1.5630, -1.5805, -1.5805,  ..., -1.5455, -1.5455, -1.5630],\n",
       "           ...,\n",
       "           [-1.4930, -1.4755, -1.4580,  ..., -1.5280, -1.5455, -1.5455],\n",
       "           [-1.4930, -1.4755, -1.4580,  ..., -1.5455, -1.5455, -1.5280],\n",
       "           [-1.4930, -1.4755, -1.4580,  ..., -1.5455, -1.5455, -1.5280]],\n",
       " \n",
       "          [[-1.3164, -1.3164, -1.3164,  ..., -1.3339, -1.3513, -1.3513],\n",
       "           [-1.3164, -1.3164, -1.3164,  ..., -1.3339, -1.3513, -1.3687],\n",
       "           [-1.2990, -1.3164, -1.3513,  ..., -1.3513, -1.3513, -1.3687],\n",
       "           ...,\n",
       "           [-1.2293, -1.2119, -1.2293,  ..., -1.2990, -1.2990, -1.2990],\n",
       "           [-1.2293, -1.2119, -1.1944,  ..., -1.2990, -1.2990, -1.2816],\n",
       "           [-1.2293, -1.2119, -1.1944,  ..., -1.2990, -1.2990, -1.2816]]],\n",
       " \n",
       " \n",
       "         [[[-1.6727, -1.6727, -1.6727,  ..., -1.2103, -1.1418, -1.1075],\n",
       "           [-1.6727, -1.6727, -1.6727,  ..., -1.2103, -1.1418, -1.1075],\n",
       "           [-1.6898, -1.6898, -1.6727,  ..., -1.2445, -1.1760, -1.1418],\n",
       "           ...,\n",
       "           [-1.6727, -1.6727, -1.6384,  ..., -1.7240, -1.7240, -1.7240],\n",
       "           [-1.6727, -1.6727, -1.6384,  ..., -1.7069, -1.7240, -1.7240],\n",
       "           [-1.6727, -1.6727, -1.6384,  ..., -1.7069, -1.7240, -1.7240]],\n",
       " \n",
       "          [[-1.5630, -1.5630, -1.5630,  ..., -1.1779, -1.1253, -1.0903],\n",
       "           [-1.5630, -1.5630, -1.5630,  ..., -1.1779, -1.1253, -1.0903],\n",
       "           [-1.5805, -1.5805, -1.5630,  ..., -1.2129, -1.1604, -1.1253],\n",
       "           ...,\n",
       "           [-1.5455, -1.5455, -1.5455,  ..., -1.6155, -1.6155, -1.6155],\n",
       "           [-1.5455, -1.5455, -1.5455,  ..., -1.5980, -1.6155, -1.6155],\n",
       "           [-1.5455, -1.5455, -1.5455,  ..., -1.5980, -1.6155, -1.6155]],\n",
       " \n",
       "          [[-1.2990, -1.2990, -1.2990,  ..., -1.0027, -0.9678, -0.9330],\n",
       "           [-1.2990, -1.2990, -1.2990,  ..., -1.0027, -0.9678, -0.9330],\n",
       "           [-1.3164, -1.3164, -1.2990,  ..., -1.0376, -0.9853, -0.9504],\n",
       "           ...,\n",
       "           [-1.3339, -1.3339, -1.3164,  ..., -1.3164, -1.3164, -1.3164],\n",
       "           [-1.3339, -1.3339, -1.3164,  ..., -1.2990, -1.3164, -1.3164],\n",
       "           [-1.3339, -1.3339, -1.3164,  ..., -1.2990, -1.3164, -1.3164]]]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ResNet18',\n",
       " ResNet18(\n",
       "   (resnet): ResNet(\n",
       "     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     (layer1): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (layer2): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (layer3): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (layer4): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "     (fc): Sequential(\n",
       "       (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Dropout(p=0.5, inplace=False)\n",
       "       (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "       (4): Softmax(dim=1)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_models[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
